{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab09 - XOR. Logistic Regression - Eager Execution\n",
    " * XOR문제를 Deep Neural Network을 통해 풀어보고, Tensorboard에 출력해 보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기본 Library 선언 및 Tensorflow 버전 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T18:19:15.839697Z",
     "start_time": "2021-02-23T18:19:15.816726Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(777)\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 강의 Data\n",
    " * x_data가 2차원 배열이기에 2차원 공간에 표현하여 x1과 x2를 기준으로 y_data를 0과 1로 구분하는 예제입니다.\n",
    " * 붉은색과 푸른색으로 0과 1을 표시해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T18:19:16.204689Z",
     "start_time": "2021-02-23T18:19:15.842659Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'x2')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_data = [[0,0],\n",
    "          [0,1],\n",
    "          [1,0],\n",
    "          [1,1]]\n",
    "y_data = [[0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [0]]\n",
    "\n",
    "plt.scatter(x_data[0][0],x_data[0][1],c='red',marker='^')\n",
    "plt.scatter(x_data[3][0],x_data[3][1],c='red',marker='^')\n",
    "plt.scatter(x_data[1][0],x_data[1][1],c='blue',marker='^')\n",
    "plt.scatter(x_data[2][0],x_data[2][1],c='blue',marker='^')\n",
    "\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 Data를 기준으로 XOR처리를 위한 모델을 만들도록 하겠습니다.\n",
    "\n",
    " * 위의 Data를 4Layer의 Neural Network를 통해 학습시킨 후 모델을 생성합니다.\n",
    " * Tensorboard --logdir=./logs/ 실행합니다.\n",
    " * summary값을 logs폴더에 저정하고 아래 명령어로 실행해서 확인한다.(http://0.0.0.0:6006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T18:19:16.221644Z",
     "start_time": "2021-02-23T18:19:16.208678Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_data,y_data)).batch(len(x_data))\n",
    "\n",
    "def preprocess_data(features,labels):\n",
    "    features = tf.cast(features,tf.float32)\n",
    "    labels = tf.cast(labels,tf.float32)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * summary값을 logs폴더에 저장하고 아래 명령어로 실행해서 확인한다. (http://0.0.0.0:6006)\n",
    " * tensorboard --logdir=./logs/xor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T18:19:16.252560Z",
     "start_time": "2021-02-23T18:19:16.227629Z"
    }
   },
   "outputs": [],
   "source": [
    "log_path = './logs/xor'\n",
    "writer = tf.summary.create_file_writer(log_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Neural Network를 통해 XOR해결\n",
    "\n",
    " * 위의 Data를 4Layer의 Neural Network를 통해 학습시킨 후 모델을 생성합니다.\n",
    " * 각각의 값을 Histogram으로 Tensorboard에 저장한다. (Model)\n",
    " * 각각의 값을 Scalar값으로 Tensorboard에 저장한다. (Cost, Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T18:19:16.300431Z",
     "start_time": "2021-02-23T18:19:16.258546Z"
    }
   },
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random.normal((2,10)),name='weight1')\n",
    "b1 = tf.Variable(tf.random.normal((10,)),name='bias1')\n",
    "\n",
    "W2 = tf.Variable(tf.random.normal((10,10)),name='weight2')\n",
    "b2 = tf.Variable(tf.random.normal((10,)),name='bias2')\n",
    "\n",
    "W3 = tf.Variable(tf.random.normal((10,10)),name='weight3')\n",
    "b3 = tf.Variable(tf.random.normal((10,)),name='bias3')\n",
    "\n",
    "W4 = tf.Variable(tf.random.normal((10,1)),name='weight4')\n",
    "b4 = tf.Variable(tf.random.normal((1,)),name='bias4')\n",
    "\n",
    "def neural_net(features,step):\n",
    "    layer1 = tf.sigmoid(tf.matmul(features,W1) + b1)\n",
    "    layer2 = tf.sigmoid(tf.matmul(layer1,W2) + b2)\n",
    "    layer3 = tf.sigmoid(tf.matmul(layer2,W3) + b3)\n",
    "    hypothesis = tf.sigmoid(tf.matmul(layer3,W4) + b4)\n",
    "    \n",
    "    with writer.as_default():\n",
    "        tf.summary.histogram('weights1',W1,step=step)\n",
    "        tf.summary.histogram('biases1',b1,step=step)\n",
    "        tf.summary.histogram('layer1',layer1,step=step)\n",
    "        \n",
    "        tf.summary.histogram('weights2',W2,step=step)\n",
    "        tf.summary.histogram('biases2',b2,step=step)\n",
    "        tf.summary.histogram('layer2',layer2,step=step)\n",
    "        \n",
    "        tf.summary.histogram('weights3',W3,step=step)\n",
    "        tf.summary.histogram('biases3',b3,step=step)\n",
    "        tf.summary.histogram('layer3',layer3,step=step)\n",
    "        \n",
    "        tf.summary.histogram('weights4',W4,step=step)\n",
    "        tf.summary.histogram('biases',b4,step=step)\n",
    "        tf.summary.histogram('hypothesis',hypothesis,step=step)\n",
    "    return hypothesis\n",
    "\n",
    "def loss_fn(hypothesis,labels):\n",
    "    cost = -tf.reduce_mean(labels * tf.math.log(hypothesis) + (1-labels) * tf.math.log(1-hypothesis))\n",
    "    with writer.as_default():\n",
    "        tf.summary.scalar('loss',cost,step=step)\n",
    "    return cost\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "def accuracy_fn(hypothesis,labels):\n",
    "    predicted = tf.cast(hypothesis > 0.5,dtype=tf.float32)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,labels),dtype=tf.float32))\n",
    "    return accuracy\n",
    "\n",
    "def grad(hypothesis,features,labels,step):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss_fn(neural_net(features,step),labels)\n",
    "    return tape.gradient(loss_value,[W1,W2,W3,W4,b1,b2,b3,b4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T18:22:47.926299Z",
     "start_time": "2021-02-23T18:19:16.302427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0,Loss: 0.9517\n",
      "iter: 50,Loss: 0.6936\n",
      "iter: 100,Loss: 0.6923\n",
      "iter: 150,Loss: 0.6912\n",
      "iter: 200,Loss: 0.6901\n",
      "iter: 250,Loss: 0.6890\n",
      "iter: 300,Loss: 0.6879\n",
      "iter: 350,Loss: 0.6867\n",
      "iter: 400,Loss: 0.6855\n",
      "iter: 450,Loss: 0.6842\n",
      "iter: 500,Loss: 0.6827\n",
      "iter: 550,Loss: 0.6811\n",
      "iter: 600,Loss: 0.6793\n",
      "iter: 650,Loss: 0.6772\n",
      "iter: 700,Loss: 0.6749\n",
      "iter: 750,Loss: 0.6722\n",
      "iter: 800,Loss: 0.6690\n",
      "iter: 850,Loss: 0.6654\n",
      "iter: 900,Loss: 0.6611\n",
      "iter: 950,Loss: 0.6561\n",
      "iter: 1000,Loss: 0.6502\n",
      "iter: 1050,Loss: 0.6432\n",
      "iter: 1100,Loss: 0.6349\n",
      "iter: 1150,Loss: 0.6251\n",
      "iter: 1200,Loss: 0.6134\n",
      "iter: 1250,Loss: 0.5992\n",
      "iter: 1300,Loss: 0.5821\n",
      "iter: 1350,Loss: 0.5612\n",
      "iter: 1400,Loss: 0.5357\n",
      "iter: 1450,Loss: 0.5047\n",
      "iter: 1500,Loss: 0.4677\n",
      "iter: 1550,Loss: 0.4248\n",
      "iter: 1600,Loss: 0.3774\n",
      "iter: 1650,Loss: 0.3281\n",
      "iter: 1700,Loss: 0.2798\n",
      "iter: 1750,Loss: 0.2356\n",
      "iter: 1800,Loss: 0.1971\n",
      "iter: 1850,Loss: 0.1649\n",
      "iter: 1900,Loss: 0.1385\n",
      "iter: 1950,Loss: 0.1173\n",
      "iter: 2000,Loss: 0.1003\n",
      "iter: 2050,Loss: 0.0865\n",
      "iter: 2100,Loss: 0.0754\n",
      "iter: 2150,Loss: 0.0663\n",
      "iter: 2200,Loss: 0.0588\n",
      "iter: 2250,Loss: 0.0526\n",
      "iter: 2300,Loss: 0.0474\n",
      "iter: 2350,Loss: 0.0429\n",
      "iter: 2400,Loss: 0.0392\n",
      "iter: 2450,Loss: 0.0359\n",
      "iter: 2500,Loss: 0.0331\n",
      "iter: 2550,Loss: 0.0306\n",
      "iter: 2600,Loss: 0.0285\n",
      "iter: 2650,Loss: 0.0265\n",
      "iter: 2700,Loss: 0.0248\n",
      "iter: 2750,Loss: 0.0233\n",
      "iter: 2800,Loss: 0.0220\n",
      "iter: 2850,Loss: 0.0207\n",
      "iter: 2900,Loss: 0.0196\n",
      "iter: 2950,Loss: 0.0186\n",
      "Testset Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "epochs = 3000\n",
    "\n",
    "for step in range(epochs):\n",
    "    for features, labels in dataset:\n",
    "        features, labels = preprocess_data(features,labels)\n",
    "        grads = grad(neural_net(features,step),features,labels,step)\n",
    "        optimizer.apply_gradients(grads_and_vars=zip(grads,[W1,W2,W3,W4,b1,b2,b3,b4]))\n",
    "        if step % 50 == 0:\n",
    "            loss_value = loss_fn(neural_net(features,step),labels)\n",
    "            print('iter: {},Loss: {:.4f}'.format(step,loss_value))\n",
    "\n",
    "x_data, y_data = preprocess_data(x_data,y_data)\n",
    "test_acc = accuracy_fn(neural_net(x_data,step),y_data)\n",
    "print('Testset Accuracy: {:.4f}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) Jupyter Notebook에서 Tensorboard 실행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T18:22:47.941262Z",
     "start_time": "2021-02-23T18:22:47.930325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the Tensorboard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T18:22:47.973174Z",
     "start_time": "2021-02-23T18:22:47.948241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 3780), started 0:04:37 ago. (Use '!kill 3780' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ae24d4391fa39d7b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ae24d4391fa39d7b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''Start TensorBoard through the command line or within a notebook experience. \n",
    "The two interfaces are generally the same. In notebooks, use the %tensorboard line magic. \n",
    "On the command line, run the same command without \"%\".'''\n",
    "\n",
    "%tensorboard --logdir logs/xor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simon_env",
   "language": "python",
   "name": "simon_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
