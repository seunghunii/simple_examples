{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of Features and Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T12:57:45.449000Z",
     "start_time": "2021-01-31T12:57:45.411000Z"
    }
   },
   "outputs": [],
   "source": [
    "# code from feature_selection/find_signature.py\n",
    "import pickle\n",
    "import numpy\n",
    "import os\n",
    "numpy.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T12:58:36.429000Z",
     "start_time": "2021-01-31T12:58:36.170000Z"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/rsh15/Desktop/seunghuni/udacity/ud120-projects/')\n",
    "words_file = \"text_learning/your_word_data.pkl\" \n",
    "authors_file = \"text_learning/your_email_authors.pkl\"\n",
    "word_data = pickle.load( open(words_file, \"r\"))\n",
    "authors = pickle.load( open(authors_file, \"r\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T13:00:16.839000Z",
     "start_time": "2021-01-31T13:00:14.497000Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(word_data, authors, test_size=0.1,\n",
    "                                                                            random_state=42)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                             stop_words='english')\n",
    "features_train = vectorizer.fit_transform(features_train)\n",
    "features_test  = vectorizer.transform(features_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T13:00:20.853000Z",
     "start_time": "2021-01-31T13:00:20.813000Z"
    }
   },
   "outputs": [],
   "source": [
    "features_train = features_train[:150].toarray()\n",
    "labels_train   = labels_train[:150]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy of your Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T13:04:41.218000Z",
     "start_time": "2021-01-31T13:04:40.756000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9590443686006825"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(features_train,labels_train).score(features_test,labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify the Most Powerful Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T13:06:25.451000Z",
     "start_time": "2021-01-31T13:06:25.401000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , ..., 0.07495003, 0.13402829,\n",
       "       0.76470588])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.sort(dt.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T13:11:20.948000Z",
     "start_time": "2021-01-31T13:11:20.920000Z"
    }
   },
   "outputs": [],
   "source": [
    "dfs = [np.arange(0,len(dt.feature_importances_)),dt.feature_importances_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T13:12:39.224000Z",
     "start_time": "2021-01-31T13:12:36.855000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33614</th>\n",
       "      <td>33614.0</td>\n",
       "      <td>0.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33953</th>\n",
       "      <td>33953.0</td>\n",
       "      <td>0.134028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26874</th>\n",
       "      <td>26874.0</td>\n",
       "      <td>0.074950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19652</th>\n",
       "      <td>19652.0</td>\n",
       "      <td>0.026316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25244</th>\n",
       "      <td>25244.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1\n",
       "33614  33614.0  0.764706\n",
       "33953  33953.0  0.134028\n",
       "26874  26874.0  0.074950\n",
       "19652  19652.0  0.026316\n",
       "25244  25244.0  0.000000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dfs).T.sort_values(1,ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use TfIdf to get the Most important word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T13:22:57.695000Z",
     "start_time": "2021-01-31T13:22:57.587000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'sshacklensf'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[33614]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove, Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T13:49:51.455000Z",
     "start_time": "2021-01-31T13:49:50.288000Z"
    }
   },
   "outputs": [],
   "source": [
    "# preperation\n",
    "# code from text learning - https://github.com/seunghunii/simple_examples/blob/master/2.Lesson10-Text%20Learning.ipynb\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import string\n",
    "stemmer = SnowballStemmer('english')\n",
    "os.chdir('C:/Users/rsh15/Desktop/seunghuni/udacity/ud120-projects/text_learning/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T13:49:51.698000Z",
     "start_time": "2021-01-31T13:49:51.656000Z"
    }
   },
   "outputs": [],
   "source": [
    "def parseOutText(f):\n",
    "    \"\"\" given an opened email file f, parse out all text below the\n",
    "        metadata block at the top\n",
    "        (in Part 2, you will also add stemming capabilities)\n",
    "        and return a string that contains all the words\n",
    "        in the email (space-separated) \n",
    "        \n",
    "        example use case:\n",
    "        f = open(\"email_file_name.txt\", \"r\")\n",
    "        text = parseOutText(f)\"\"\"\n",
    "    \n",
    "    f.seek(0)  ### go back to beginning of file (annoying)\n",
    "    all_text = f.read()\n",
    "\n",
    "    ### split off metadata\n",
    "    content = all_text.split(\"X-FileName:\")\n",
    "    words = \"\"\n",
    "    if len(content) > 1:\n",
    "        ### remove punctuation\n",
    "        text_string = content[1].translate(string.maketrans(\"\", \"\"), string.punctuation)\n",
    "\n",
    "        ### project part 2: comment out the line below\n",
    "        \n",
    "        ### split the text string into individual words, stem each word,\n",
    "        ### and append the stemmed word to words (make sure there's a single\n",
    "        ### space between each stemmed word)\n",
    "        for word in text_string.split():\n",
    "            # stem the word and add it to words\n",
    "            words += stemmer.stem(word) + ' '       \n",
    "        \n",
    "    return words[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T13:58:23.916000Z",
     "start_time": "2021-01-31T13:57:39.372000Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_rid_of_signature_words(sw):\n",
    "    with open(\"from_sara.txt\", \"r\") as from_sara, open(\"from_chris.txt\", \"r\") as from_chris:\n",
    "\n",
    "        from_data = []\n",
    "        word_data = []\n",
    "\n",
    "        ### temp_counter is a way to speed up the development--there are\n",
    "        ### thousands of emails from Sara and Chris, so running over all of them\n",
    "        ### can take a long time\n",
    "        ### temp_counter helps you only look at the first 200 emails in the list so you\n",
    "        ### can iterate your modifications quicker\n",
    "        temp_counter = 0\n",
    "\n",
    "\n",
    "        for name, from_person in [(\"sara\", from_sara), (\"chris\", from_chris)]:\n",
    "            for path in from_person:\n",
    "                ### only look at first 200 emails when developing\n",
    "                ### once everything is working, remove this line to run over full dataset\n",
    "\n",
    "                #temp_counter += 1\n",
    "                if temp_counter < 200:\n",
    "                    path = os.path.join('..', path[:-1])\n",
    "\n",
    "                    with open(path, 'r') as email:\n",
    "                        ### use parseOutText to extract the text from the opened email\n",
    "                        text = parseOutText(email)\n",
    "\n",
    "                        ### use str.replace() to remove any instances of the words\n",
    "                        ### [\"sara\", \"shackleton \", \"chris\", \"germani\"]\n",
    "                        for word in sw:\n",
    "                            if(word in text):\n",
    "                                text = text.replace(word, \"\")\n",
    "\n",
    "                        ### append the text to word_data\n",
    "                        tmp_txt = text.replace('\\n',' ').strip()\n",
    "                        #tmp_txt = tmp_txt.replace(' {2,}','').lower()\n",
    "                        word_data.append(tmp_txt)\n",
    "\n",
    "                        ### append a 0 to from_data if email is from Sara, and 1 if email is from Chris\n",
    "                        if name=='sara':\n",
    "                            from_data.append(0)\n",
    "                        else:\n",
    "                            from_data.append(1)\n",
    "    return word_data, from_data\n",
    "                            \n",
    "sw = [\"sara\", \"shackleton\", \"chris\", \"germani\",'sshacklensf']\n",
    "word_data, from_data = get_rid_of_signature_words(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T13:58:57.882000Z",
     "start_time": "2021-01-31T13:58:55.428000Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "new_features_train, new_features_test, new_labels_train, new_labels_test = train_test_split(word_data, from_data,\n",
    "                                                                                            test_size=0.1,random_state=42)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                             stop_words='english')\n",
    "new_features_train = vectorizer.fit_transform(new_features_train)\n",
    "new_features_test  = vectorizer.transform(new_features_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T13:58:58.648000Z",
     "start_time": "2021-01-31T13:58:58.614000Z"
    }
   },
   "outputs": [],
   "source": [
    "new_features_train = new_features_train[:150].toarray()\n",
    "new_labels_train   = new_labels_train[:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T13:59:00.545000Z",
     "start_time": "2021-01-31T13:59:00.032000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9687144482366326"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(new_features_train,new_labels_train).score(new_features_test,new_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T13:59:04.459000Z",
     "start_time": "2021-01-31T13:59:02.271000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14343</th>\n",
       "      <td>14343.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>8674.0</td>\n",
       "      <td>0.162602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16268</th>\n",
       "      <td>16268.0</td>\n",
       "      <td>0.093809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14337</th>\n",
       "      <td>14337.0</td>\n",
       "      <td>0.050607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13862</th>\n",
       "      <td>13862.0</td>\n",
       "      <td>0.026316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25250</th>\n",
       "      <td>25250.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25249</th>\n",
       "      <td>25249.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25248</th>\n",
       "      <td>25248.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25247</th>\n",
       "      <td>25247.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25246</th>\n",
       "      <td>25246.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1\n",
       "14343  14343.0  0.666667\n",
       "8674    8674.0  0.162602\n",
       "16268  16268.0  0.093809\n",
       "14337  14337.0  0.050607\n",
       "13862  13862.0  0.026316\n",
       "25250  25250.0  0.000000\n",
       "25249  25249.0  0.000000\n",
       "25248  25248.0  0.000000\n",
       "25247  25247.0  0.000000\n",
       "25246  25246.0  0.000000"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = [np.arange(0,len(dt.feature_importances_)),dt.feature_importances_]\n",
    "pd.DataFrame(dfs).T.sort_values(1,ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T13:59:17.877000Z",
     "start_time": "2021-01-31T13:59:17.764000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'cgermannsf'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[14343]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Important Feature Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T14:05:56.077000Z",
     "start_time": "2021-01-31T14:05:09.994000Z"
    }
   },
   "outputs": [],
   "source": [
    "sw = [\"sara\", \"shackleton\", \"chris\", \"germani\",'sshacklensf','cgermannsf']\n",
    "word_data, from_data = get_rid_of_signature_words(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T14:06:29.260000Z",
     "start_time": "2021-01-31T14:06:26.774000Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "new_features_train2, new_features_test2, new_labels_train2, new_labels_test2 = train_test_split(word_data, from_data,\n",
    "                                                                                            test_size=0.1,random_state=42)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                             stop_words='english')\n",
    "new_features_train2 = vectorizer.fit_transform(new_features_train2)\n",
    "new_features_test2  = vectorizer.transform(new_features_test2).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T14:06:29.564000Z",
     "start_time": "2021-01-31T14:06:29.522000Z"
    }
   },
   "outputs": [],
   "source": [
    "new_features_train2 = new_features_train2[:150].toarray()\n",
    "new_labels_train2   = new_labels_train2[:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T14:06:30.241000Z",
     "start_time": "2021-01-31T14:06:29.794000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8253697383390216"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(new_features_train2,new_labels_train2).score(new_features_test2,new_labels_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T14:06:32.611000Z",
     "start_time": "2021-01-31T14:06:30.503000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21323</th>\n",
       "      <td>21323.0</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18849</th>\n",
       "      <td>18849.0</td>\n",
       "      <td>0.186927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11975</th>\n",
       "      <td>11975.0</td>\n",
       "      <td>0.105379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22546</th>\n",
       "      <td>22546.0</td>\n",
       "      <td>0.084069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29690</th>\n",
       "      <td>29690.0</td>\n",
       "      <td>0.061295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33905</th>\n",
       "      <td>33905.0</td>\n",
       "      <td>0.047407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17248</th>\n",
       "      <td>17248.0</td>\n",
       "      <td>0.042667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14480</th>\n",
       "      <td>14480.0</td>\n",
       "      <td>0.026280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30831</th>\n",
       "      <td>30831.0</td>\n",
       "      <td>0.025529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26873</th>\n",
       "      <td>26873.0</td>\n",
       "      <td>0.024810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1\n",
       "21323  21323.0  0.363636\n",
       "18849  18849.0  0.186927\n",
       "11975  11975.0  0.105379\n",
       "22546  22546.0  0.084069\n",
       "29690  29690.0  0.061295\n",
       "33905  33905.0  0.047407\n",
       "17248  17248.0  0.042667\n",
       "14480  14480.0  0.026280\n",
       "30831  30831.0  0.025529\n",
       "26873  26873.0  0.024810"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = [np.arange(0,len(dt.feature_importances_)),dt.feature_importances_]\n",
    "pd.DataFrame(dfs).T.sort_values(1,ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T14:06:32.973000Z",
     "start_time": "2021-01-31T14:06:32.872000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'cgermanyenroncom'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[14343]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oldpy",
   "language": "python",
   "name": "oldpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
