{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T05:25:54.268000Z",
     "start_time": "2021-02-02T05:25:54.238000Z"
    }
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import logging\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.metrics import classification_report,confusion_matrix,f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T04:21:08.025000Z",
     "start_time": "2021-02-02T04:21:07.991000Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T04:21:13.668000Z",
     "start_time": "2021-02-02T04:21:08.831000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size:\n",
      "n_samples: 1288\n",
      "n_features: 1850\n",
      "n_classes: 7\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Download the data, if not already on disk and load it as numpy arrays\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "\n",
    "# introspect the images arrays to find the shapes (for plotting)\n",
    "n_samples, h, w = lfw_people.images.shape\n",
    "np.random.seed(42)\n",
    "\n",
    "# for machine learning we use the data directly (as relative pixel\n",
    "# position info is ignored by this model)\n",
    "X = lfw_people.data\n",
    "n_features = X.shape[1]\n",
    "\n",
    "# the label to predict is the id of the person\n",
    "y = lfw_people.target\n",
    "target_names = lfw_people.target_names\n",
    "n_classes = target_names.shape[0]\n",
    "\n",
    "print \"Total dataset size:\"\n",
    "print \"n_samples: %d\" % n_samples\n",
    "print \"n_features: %d\" % n_features\n",
    "print \"n_classes: %d\" % n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T04:23:22.342000Z",
     "start_time": "2021-02-02T04:23:22.109000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting the top 150 eigenfaces from 966 faces\n",
      "done in 0.170s\n",
      "Projecting the input data on the eigenfaces orthonormal basis\n",
      "done in 0.018s\n"
     ]
    }
   ],
   "source": [
    "# Split into a training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "###############################################################################\n",
    "# Compute a PCA (eigenfaces) on the face dataset (treated as unlabeled\n",
    "# dataset): unsupervised feature extraction / dimensionality reduction\n",
    "n_components = 150\n",
    "\n",
    "print \"Extracting the top %d eigenfaces from %d faces\" % (n_components, X_train.shape[0])\n",
    "t0 = time()\n",
    "pca = PCA(n_components=n_components, whiten=True).fit(X_train)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "\n",
    "eigenfaces = pca.components_.reshape((n_components, h, w))\n",
    "\n",
    "print \"Projecting the input data on the eigenfaces orthonormal basis\"\n",
    "t0 = time()\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explained Variance of Each pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T04:25:49.464000Z",
     "start_time": "2021-02-02T04:25:49.425000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first component explained 0.193\n",
      "second component explained 0.151\n"
     ]
    }
   ],
   "source": [
    "var_ratio = pca.explained_variance_ratio_\n",
    "print('first component explained {0}'.format(round(var_ratio[0],3)))\n",
    "print('second component explained {0}'.format(round(var_ratio[1],3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 Score vs. No. of PCs Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T06:05:03.153000Z",
     "start_time": "2021-02-02T06:03:00.389000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10      Ariel Sharon       0.10      0.15      0.12        13\n",
      "15      Ariel Sharon       0.24      0.46      0.32        13\n",
      "25      Ariel Sharon       0.60      0.69      0.64        13\n",
      "50      Ariel Sharon       0.67      0.77      0.71        13\n",
      "100      Ariel Sharon       0.64      0.69      0.67        13\n",
      "250      Ariel Sharon       0.56      0.69      0.62        13\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for k in [10, 15, 25, 50, 100, 250]:\n",
    "    pca = PCA(n_components=k,whiten=True).fit(X_train)\n",
    "\n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    \n",
    "    param_grid = {\n",
    "         'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "          'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1],\n",
    "          }\n",
    "    # for sklearn version 0.16 or prior, the class_weight parameter value is 'auto'\n",
    "    clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid)\n",
    "    clf = clf.fit(X_train_pca, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test_pca)\n",
    "    \n",
    "    print '{0} '.format(k) + classification_report(y_test, y_pred, target_names=target_names).split('\\n')[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oldpy",
   "language": "python",
   "name": "oldpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
